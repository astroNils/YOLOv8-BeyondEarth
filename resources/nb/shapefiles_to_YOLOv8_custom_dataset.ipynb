{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "528f123c-71aa-4898-bd7c-d326e736526f",
   "metadata": {},
   "source": [
    "## From shapefiles to a custom dataset in YOLOv8\n",
    "\n",
    "The conversion from shapefiles to training data follows the same procedure as for the generation of training data for the Mask R-CNN model architecture: \n",
    "\n",
    "1. Select all of the shapefiles and all of the region of mapping (not the), and clip boulders to it (clip to patches).\n",
    "2. Select already generated pickle files (contain information to tile rasters).\n",
    "3. Read all boulder shapefiles and pickle files and concatenate them in one GeoDataframe/Dataframe (for each of them)\n",
    "4. Specify main path to rasters.\n",
    "5. Split in train-validation-test split based on selected percentages.\n",
    "6. Tile rasters based on mapped patches.\n",
    "7. Update absolute path to boulder mapping\n",
    "8. Tile shapefiles from dataframe\n",
    "9. Save pickle (in case you want to re-run it)\n",
    "10. Generate YOLOv8 custom dataset for import during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5a91bd4-2a42-499c-a465-71fec16c777d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shapely\n",
    "import sys\n",
    "import skimage\n",
    "import pycocotools.mask as mask_util\n",
    "\n",
    "from shptools_BOULDERING import shp, geometry as shp_geom, geomorph as shp_geomorph, annotations as shp_anno, metrics as shp_metrics\n",
    "from rastertools_BOULDERING import raster, metadata as raster_metadata, crs as raster_crs\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79ec31b-0cb4-42de-97dc-37c34495bf6d",
   "metadata": {},
   "source": [
    "Steps 1 to 8 are already described at https://github.com/astroNils/MLtools/blob/main/resources/nb/PREPROCESSING_BOULDERING.ipynb. Just follow the same step, and you will end up with a pandas dataframe with all of the information you need! I am just directly loading the dataframe below. <br>\n",
    "\n",
    "We here need to focus on converting the masks representing the outlines of boulders into the YOLOv8 format. You can learn more about the format here: https://docs.ultralytics.com/datasets/segment/#supported-dataset-formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7997bb5-8774-4bf4-a25d-f49cad783361",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = Path(\"D:/BOULDERING/data/preprocessing_Jan2024/json/Jan2024-Mars-Moon-Earth-mask-0px-windows.json\") # change to your local path\n",
    "img_dir = Path(\"D:/BOULDERING/data/preprocessing_Jan2024\") # change to your local path where tiled images have been saved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb4fa6de-b674-414e-a65d-23f34d005945",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8591a86-d5b2-4e70-be6d-3a0e2f5cc7a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dataset</th>\n",
       "      <th>annotations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M1221383405_1718_image.png</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>[{'bbox': [142.0, 498.0, 151.0, 500.0], 'bbox_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M121627645_01013_image.png</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>[{'bbox': [57.0, 490.0, 61.0, 496.0], 'bbox_mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M139694087LE_0792_image.png</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "      <td>[{'bbox': [461.0, 335.0, 469.0, 342.0], 'bbox_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M121267110_01679_image.png</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "      <td>[{'bbox': [282.0, 487.0, 288.0, 491.0], 'bbox_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M121267110_01425_image.png</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>4</td>\n",
       "      <td>validation</td>\n",
       "      <td>[{'bbox': [383.0, 387.0, 394.0, 400.0], 'bbox_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     file_name  height  width  image_id     dataset  \\\n",
       "0   M1221383405_1718_image.png     500    500         0       train   \n",
       "1   M121627645_01013_image.png     500    500         1       train   \n",
       "2  M139694087LE_0792_image.png     500    500         2       train   \n",
       "3   M121267110_01679_image.png     500    500         3       train   \n",
       "4   M121267110_01425_image.png     500    500         4  validation   \n",
       "\n",
       "                                         annotations  \n",
       "0  [{'bbox': [142.0, 498.0, 151.0, 500.0], 'bbox_...  \n",
       "1  [{'bbox': [57.0, 490.0, 61.0, 496.0], 'bbox_mo...  \n",
       "2  [{'bbox': [461.0, 335.0, 469.0, 342.0], 'bbox_...  \n",
       "3  [{'bbox': [282.0, 487.0, 288.0, 491.0], 'bbox_...  \n",
       "4  [{'bbox': [383.0, 387.0, 394.0, 400.0], 'bbox_...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6674a3-7d08-48fd-b3a2-cad857a51cb1",
   "metadata": {},
   "source": [
    "We have the filenames, heights, and widths (you might have 512), image IDs, whether the tile is part of the train, validation, or test datasets, and then some information about the bounding boxes and masks of the outlines. So far, it is the same as for Mask R-CNN. <br>\n",
    "\n",
    "If you look into the annotations, you can see that the segmentation (i.e., the masks) are saved as the RLE format (https://en.wikipedia.org/wiki/Run-length_encoding), which is the segmentation format used by Mask R-CNN. This is the part we want to change. Let's have a close look at how a single RLE string can be converted as YOLO segmentation text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "80437572-5f5f-4bbd-bc09-8e2f23cb0fba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bbox': [64.0, 485.0, 70.0, 491.0],\n",
       " 'bbox_mode': 0,\n",
       " 'category_id': 0,\n",
       " 'segmentation': {'size': [500, 500], 'counts': 'Vgo03a?2M1001O1Mc_a6'}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = df.iloc[0]\n",
    "anno = row[\"annotations\"]\n",
    "anno[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "54dd7307-fc7f-4356-b7ea-058de1fd4e5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'size': [500, 500], 'counts': 'Vgo03a?2M1001O1Mc_a6'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anno[10][\"segmentation\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140b438a-8e0e-4b16-a1a4-9657877eba48",
   "metadata": {},
   "source": [
    "The following command can be used to convert a binary mask into a polygon (x and y coordinates). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "96f7322c-e816-4b95-b38d-70a137ca85a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_mask_to_polygon(binary_mask):\n",
    "    \"\"\"Converts a binary mask to polygon representation\n",
    "    Args:\n",
    "        binary_mask: a 2D binary numpy array where '1's represent the object\n",
    "        tolerance: Maximum distance from original points of polygon to approximated\n",
    "            polygonal chain. If tolerance is 0, the original coordinate array is returned.\n",
    "    \"\"\"\n",
    "    polygon = []\n",
    "    # pad mask to close contours of shapes which start and end at an edge\n",
    "    padded_binary_mask = np.pad(binary_mask, pad_width=1, mode='constant', constant_values=0)\n",
    "    contours = skimage.measure.find_contours(padded_binary_mask, 0.5)\n",
    "\n",
    "    # yolo can produce a mask where pixels are not interconnected\n",
    "    # in this case the following line does not work\n",
    "    contours = np.subtract(contours, 1)\n",
    "    contour = np.flip(contours[0], axis=1) # should be interconnected\n",
    "    return contour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "243a0954-a4c2-4d31-a995-65f3cb2e8cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rle = anno[10][\"segmentation\"]\n",
    "m = skimage.morphology.remove_small_holes(mask_util.decode(rle).astype(\"bool\")) # mask_util decode rle into binary mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4481cd76-3f8c-48a8-9d68-5eca7b6fa90c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1cf43892190>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(m) # you can see a boulder in the lower left corner."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f266f6-bed8-45a2-9e70-51e2772376fd",
   "metadata": {},
   "source": [
    "## Generation of the YOLOv8 segmentation text file for one boulder outline\n",
    "\n",
    "#### binary mask to polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c58c313d-a587-4e88-992e-f742a93fa607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 68. , 490.5],\n",
       "       [ 67. , 490.5],\n",
       "       [ 66. , 490.5],\n",
       "       [ 65. , 490.5],\n",
       "       [ 64.5, 490. ],\n",
       "       [ 64.5, 489. ],\n",
       "       [ 64. , 488.5],\n",
       "       [ 63.5, 488. ],\n",
       "       [ 63.5, 487. ],\n",
       "       [ 63.5, 486. ],\n",
       "       [ 64. , 485.5],\n",
       "       [ 65. , 485.5],\n",
       "       [ 65.5, 485. ],\n",
       "       [ 66. , 484.5],\n",
       "       [ 67. , 484.5],\n",
       "       [ 67.5, 485. ],\n",
       "       [ 68. , 485.5],\n",
       "       [ 68.5, 486. ],\n",
       "       [ 69. , 486.5],\n",
       "       [ 69.5, 487. ],\n",
       "       [ 69.5, 488. ],\n",
       "       [ 69. , 488.5],\n",
       "       [ 68.5, 489. ],\n",
       "       [ 68.5, 490. ],\n",
       "       [ 68. , 490.5]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contour = binary_mask_to_polygon(m)\n",
    "contour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316e4b6f-84e3-4fb7-8a60-3f0e6cbbf988",
   "metadata": {},
   "source": [
    "The mask is now converted to set of x and y coordinates.\n",
    "\n",
    "#### polygon to YOLOv8 string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aa8c7e9f-cbdc-4bdc-a583-502959c24e2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0 0.136 0.981 0.134 0.981 0.132 0.981 0.13 0.981 0.129 0.98 0.129 0.978 0.128 0.977 0.127 0.976 0.127 0.974 0.127 0.972 0.128 0.971 0.13 0.971 0.131 0.97 0.132 0.969 0.134 0.969 0.135 0.97 0.136 0.971 0.137 0.972 0.138 0.973 0.139 0.974 0.139 0.976 0.138 0.977 0.137 0.978 0.137 0.98 0.136 0.981\\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = np.array(contour).squeeze()\n",
    "cc = np.stack([c[:,0], c[:,1]], axis=-1) \n",
    "arr = cc.flatten() / row.height\n",
    "arr = list(arr.round(decimals = 3))\n",
    "arr.insert(0, 0)\n",
    "str_arr = [str(a) for a in arr]\n",
    "line = \" \".join(str_arr)  + \"\\n\"\n",
    "line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfe0b9a-d83b-459e-b579-e2602c81f6e1",
   "metadata": {},
   "source": [
    "https://docs.ultralytics.com/datasets/segment/#supported-dataset-formats. <br>\n",
    "\n",
    "The first number describes the object's nature. In our case, we only detect boulders, so we set 0 to all objects. NB! If you work with more than one class, this code needs to be modified! The remaining values depict the normalized x and y coordinates, so it's imÃ¥portant that the height and width in the data frame are correct! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568ce9dc-7674-4457-81eb-c4af1792200e",
   "metadata": {},
   "source": [
    "## Generation of the YOLOv8 segmentation text file for all boulder outlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641f984c-e60b-4c3e-9397-0e9cb32be2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "npixels_threshold = 6 # minimum number of pixels to be considered as a valid boulder\n",
    "image_size = 500 # change accordingly\n",
    "\n",
    "for i, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "    masks = []\n",
    "    for r in row.annotations:\n",
    "        rle = r[\"segmentation\"]\n",
    "        # to avoid holes within mask\n",
    "        masks.append(skimage.morphology.remove_small_holes(mask_util.decode(rle))) # just in case there is a hole in there. \n",
    "\n",
    "    contours = []\n",
    "    for m in masks:\n",
    "        npixels = len(m[m == 1])\n",
    "        # min, max area (max area is set to 75% of the size of the image)\n",
    "        if np.logical_and(npixels > npixels_threshold, npixels < (0.75 * image_size) * (0.75 * image_size)):\n",
    "            contours.append(binary_mask_to_polygon(m))\n",
    "        \n",
    "    txt_stem = row.file_name.replace(\"png\", \"txt\")\n",
    "    txt_filename = pre_processed_folder / row.dataset / \"labels\" / txt_stem\n",
    "    with open(txt_filename.as_posix(), \"a\") as f:\n",
    "        for contour in contours:\n",
    "            c = np.array(contour).squeeze()\n",
    "            cc = np.stack([c[:,0], c[:,1]], axis=-1) \n",
    "            arr = cc.flatten() / row.height\n",
    "            arr = list(arr.round(decimals = 3))\n",
    "            arr.insert(0, 0) # we only have one type of object to detect (boulder). If you work with more than one class, the code needs to be modified! \n",
    "            # see https://docs.ultralytics.com/datasets/segment/#supported-dataset-formats.\n",
    "            str_arr = [str(a) for a in arr]\n",
    "            line = \" \".join(str_arr)  + \"\\n\"\n",
    "            f.writelines(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f35a54-131b-4550-ad86-30e87542c275",
   "metadata": {},
   "source": [
    "This code will generate a text file per image/tile (in the same folder as the shapefiles). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967f60e3-265b-414c-873f-f0dac673dedf",
   "metadata": {},
   "source": [
    "## Generation YAML file describing where training/validation/test data is...\n",
    "The last piece of the puzzle is to create a YAML file (as below) to tell where to look for the data (this will be one of the inputs in the training of the model).\n",
    "\n",
    "```yaml\n",
    "train: D:/BOULDERING/data/yolov8/datasets/boulder2024/train/images # change to your path\r\n",
    "val: D:/BOULDERING/data/yolov8/datasets/boulder2024//validation/image # change to your path \r\n",
    "test: D:/BOULDERING/data/yolov8/datasets/boulder2024/test/imag # change to your path) \r\n",
    "nc: 1\r\n",
    "# classes (only 1)\r\n",
    "names:\r\n",
    "  0: boulder\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808e4254-3dd4-47e5-9481-0d3c3fa2868b",
   "metadata": {},
   "source": [
    "You only have to specify the path to the images. if labels are saved to `D:/BOULDERING/data/yolov8/datasets/boulder2024/train/labels`, `D:/BOULDERING/data/yolov8/datasets/boulder2024/validation/labels`, `D:/BOULDERING/data/yolov8/datasets/boulder2024/test/labels`, they will be automatically detected by YOLOv8. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fe0ac0-7ce8-4ab9-ba82-6324ffad7e65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
